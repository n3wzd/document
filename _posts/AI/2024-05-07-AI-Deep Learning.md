---
categories:
- AI
date: '2024-05-07'
title: '[AI] Deep Learning'
---

{% raw %}
딥러닝(Deep Learning)은 인공 신경망을 사용하여 복잡한 패턴을 학습하고 데이터를 모델링하는 머신러닝의 구현 방법 중 하나입니다. 딥러닝은 대규모 데이터셋에서 직접 특징을 추출하고 다층적인 구조를 사용하여 데이터의 추상적인 표현을 학습합니다. 이를 통해 딥러닝 모델은 사람보다 정확하게 이미지, 음성, 텍스트 등의 데이터를 처리하고 분류할 수 있습니다.

딥러닝의 핵심 구성 요소는 인공 신경망입니다. 인공 신경망은 생물학적 뉴런의 작동 방식에서 영감을 받아 구성된 모델로, 입력 데이터를 받아들이고 이를 처리하여 출력을 생성합니다. 딥러닝에서는 특히 심층 신경망(Deep Neural Networks)이라고도 불리는 깊은 신경망을 사용합니다. 이러한 심층 신경망은 여러 층(layer)으로 구성되어 있으며, 각 층은 이전 층의 출력을 입력으로 받아들입니다.

### vs 머신러닝
딥러닝과 머신러닝의 차이점은 다음과 같습니다.

1. **표현 학습 방법의 차이**:
    - **머신러닝**: 머신러닝은 데이터로부터 특징(feature)을 추출하고, 이러한 특징을 사용하여 모델을 학습합니다. 특징 엔지니어링(feature engineering)이 중요한 과정입니다.
    - **딥러닝**: 딥러닝은 데이터로부터 직접 특징을 학습합니다. 이를 통해 입력 데이터에서 유용한 표현을 자동으로 학습할 수 있습니다. 따라서 딥러닝은 특징 엔지니어링 과정을 크게 줄일 수 있습니다.
2. **모델의 구조적 차이**:
    - **머신러닝**: 머신러닝 모델은 주로 선형 모델, 결정 트리, SVM(Support Vector Machine) 등과 같은 상대적으로 간단한 알고리즘을 기반으로 합니다.
    - **딥러닝**: 딥러닝 모델은 다양한 신경망 아키텍처를 사용합니다. 이러한 신경망은 여러 층의 뉴런으로 구성되어 있으며, 복잡한 비선형 관계를 모델링할 수 있습니다.
3.  **학습 방법의 차이**:
    - **머신러닝**: 대부분의 머신러닝 알고리즘은 상대적으로 적은 수의 데이터로도 학습이 가능하며, 일반적으로 작은 데이터셋에 적합합니다.
    - **딥러닝**: 딥러닝은 대규모의 데이터셋과 많은 컴퓨팅 자원이 필요합니다. 일반적으로 많은 데이터를 사용하여 복잡한 모델을 학습하므로, 많은 시간과 계산 리소스가 필요합니다.

### 뉴런 (Neuron)
뉴런(Neuron)은 신경망의 기본적인 단위로, 정보를 처리하고 전달하는 역할을 합니다. 이러한 뉴런들이 모여서 신경망을 형성하며, 각 뉴런은 신경망의 계산과정에서 중요한 역할을 합니다.

가중치(weight)와 편향(bias)은 뉴런에서 사용되는 매개변수로, 입력 데이터와 뉴런 간의 연결을 특정 진행 방향으로 조절하고 신경망의 출력을 생성하는 데 사용됩니다.

1. **가중치(Weight)**:
	- 가중치는 입력 데이터와 함께 곱해지는 값으로, 해당 입력의 중요성을 나타냅니다.
	- 이미지 분류에서는 가중치가 각 픽셀의 중요도를 나타내고, 자연어 처리에서는 단어의 중요성을 나타냅니다.
2. **편향(Bias)**:
	- 편향은 각 뉴런에 더해지는 고정된 값으로, 해당 뉴런이 얼마나 쉽게 활성화되는지를 조절합니다.
	- 편향을 사용함으로써 신경망은 입력 데이터가 0인 경우에도 올바른 출력을 생성할 수 있습니다.

일반적으로 신경망에서 각 뉴런은 각각 고유한 가중치와 편향을 가집니다. 또한 각 뉴런과 이전 계층의 뉴런 간의 연결도 고유한 가중치와 편향을 가집니다.

따라서 신경망에서 각 뉴런마다 가중치와 편향은 해당 뉴런과 연결된 다른 뉴런과는 다른 값을 가지며, 이 값들은 학습 과정에서 업데이트됩니다. 이를 통해 네트워크는 입력 데이터와 가중치, 편향을 사용하여 패턴을 학습하고, 주어진 작업을 수행할 수 있습니다.

### 활성화 (Activation)
활성화 과정은 각 뉴런마다 입력된 데이터에 가중치를 곱하고 편향을 더한 후, 활성화 함수를 적용하는 과정입니다.

활성화 과정은 다음과 같습니다.
1. **가중치 합 계산**:
	- 입력된 값과 현재 뉴런의 가중치(weight)를 곱한 후, 편향(bias)을 더하여 가중치 합을 계산합니다.
2.  **활성화 함수 적용**:
	- 가중치 합을 계산한 후, 활성화 함수를 적용하여 뉴런의 출력을 생성합니다.
	- 활성화 함수를 통과한 값은 뉴런의 활성화 정도를 나타냅니다.

#### 활성화 함수(Activation Function)
활성화 함수는 데이터에 비선형성을 도입하고, 네트워크가 더 복잡한 함수를 모델링할 수 있도록 합니다.

주로 사용되는 활성화 함수는 다음과 같습니다:
- **ReLU(Rectified Linear Unit)**: 입력이 양수인 경우에는 그 값을 그대로 반환하고, 음수인 경우에는 0으로 변환합니다.
- **Leaky ReLU**: 입력이 음수인 경우에도 작은 기울기를 갖도록 ReLU를 변형한 함수입니다.
- **시그모이드(Sigmoid)**: 값의 범위를 0과 1 사이로 제한합니다.
- **하이퍼볼릭 탄젠트(Tanh)**: 값의 범위를 -1과 1 사이로 제한합니다.
- **소프트맥스(Softmax)**: 값을 각 클래스에 대한 확률로 변환합니다.

### 선형 (Linear)
선형 모델은 입력과 출력 사이의 관계를 직선으로 표현할 수 있는 모델입니다. 단순하고 계산이 빠르지만, 복잡한 패턴을 학습할 수 없습니다. 수학적으로, 선형 함수는 다음과 같이 정의됩니다:

$$
y = \mathbf{w} \cdot \mathbf{x} + b
$$

- $y$: 출력 값
- $\mathbf{w}$: 가중치 벡터
- $\mathbf{x}$: 입력 벡터
- $b$: 편향(bias)

선형 모델은 입력 값에 대한 가중치의 선형 결합으로 출력을 계산합니다. 이러한 모델은 직선적인 관계를 학습할 수 있으며, 입력 데이터와 출력 데이터가 선형적으로 분리될 수 있는 경우에만 유용합니다. 예를 들어, 선형 회귀나 로지스틱 회귀는 선형 모델에 해당됩니다.

### 비선형 (Non-linear)
비선형 모델은 입력과 출력 사이의 관계를 직선이 아닌 복잡한 곡선으로 표현할 수 있는 모델입니다. 비선형 모델은 선형 함수로는 표현할 수 없는 복잡한 패턴과 관계를 학습할 수 있습니다. 비선형성을 도입하기 위해 딥러닝에서는 주로 비선형 활성화 함수를 사용합니다.

활성화 함수는 뉴런의 출력 값을 비선형적으로 변환합니다. 일반적인 비선형 활성화 함수로는 ReLU(Rectified Linear Unit), Sigmoid, Tanh 등이 있습니다. 비선형 활성화 함수를 사용함으로써 딥러닝 모델은 복잡한 데이터 구조를 학습하고 표현할 수 있는 능력을 갖추게 됩니다. 이는 딥러닝의 강력한 성능의 핵심 요소 중 하나입니다.

예를 들어, XOR(Exclusive OR) 문제는 입력 값이 두 개의 이진 변수인 경우, 두 값이 다를 때만 출력이 1이고, 같을 때는 0이 되는 문제입니다. XOR 문제는 선형 분리가 불가능한 비선형 문제로, 단일 레이어 퍼셉트론으로 해결할 수 없습니다. 이를 해결하기 위해 다층 레이어 퍼셉트론이 필요합니다.
{% endraw %}